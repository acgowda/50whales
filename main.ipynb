{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Tejas Kamtam\n",
    "#   Anand Gowda\n",
    "#   Austin Yang\n",
    "#   Anish\n",
    "# CLEAR OUTPUTS BEFORE COMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   constants\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "N_EVAL = 1\n",
    "DATA = \"../50whales/sauce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   data processing\n",
    "import torch\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class StartingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that contains 100000 3x224x224 black images (all zeros).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data = pd.read_csv(DATA + \"/train.csv\")\n",
    "        self.data.rename(columns=self.data.iloc[0]).drop(self.data.index[0])\n",
    "        self.images = self.data.iloc[:, 0]\n",
    "        self.labels = self.data.iloc[:, 1]\n",
    "        self.transition = list(set(self.labels))\n",
    "        self.whales = self.labels.replace(self.transition, list(range(5005)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(DATA + self.path + self.images[index])\n",
    "        label = self.whales[index]\n",
    "\n",
    "        image = image.resize((448, 224))\n",
    "        image = ImageOps.grayscale(image)\n",
    "\n",
    "        #return torchvision.transforms.functional.pil_to_tensor(image), label\n",
    "        image = torchvision.transforms.ToTensor()(np.array(image))\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class StartingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic logistic regression on 224x224x3 images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size = 5, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 56 * 28, 5005)\n",
    "        # self.fc2 = nn.Linear(20020, 10010)\n",
    "        # self.fc3 = nn.Linear(10010 ,5005)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "\n",
    "        #Forward porp\n",
    "        # (n, 1, 448, 224)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        # (n, 4, 448, 224)\n",
    "        x = self.pool(x)\n",
    "        # (n, 4, 224, 112)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        # (n, 8, 224, 112)\n",
    "        x = self.pool(x)\n",
    "        # (n, 8, 112, 56)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        # (n, 16, 112, 56)\n",
    "        x = self.pool(x)\n",
    "        # (n, 16, 56, 28)\n",
    "\n",
    "        x = torch.reshape(x, (-1, 16 * 56 * 28))\n",
    "        # (n, 8 * 112 * 56)\n",
    "        x = self.fc1(x)\n",
    "        # x = F.relu(x)\n",
    "        # (n, 20020)\n",
    "        # x = self.fc2(x)\n",
    "        # x = F.relu(x)\n",
    "        # (n, 10010)\n",
    "        # x = self.fc3(x)\n",
    "        # (n, 5005)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   train func + tensorboard\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def starting_train(train_dataset, val_dataset, model, hyperparameters, n_eval, device):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model.\n",
    "\n",
    "    Args:\n",
    "        train_dataset:   PyTorch dataset containing training data.\n",
    "        val_dataset:     PyTorch dataset containing validation data.\n",
    "        model:           PyTorch model to be trained.\n",
    "        hyperparameters: Dictionary containing hyperparameters.\n",
    "        n_eval:          Interval at which we evaluate our model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get keyword arguments\n",
    "    batch_size, epochs = hyperparameters[\"batch_size\"], hyperparameters[\"epochs\"]\n",
    "\n",
    "    # Initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Initalize optimizer (for gradient descent) and loss function\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Move the model to the GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    step = 1\n",
    "\n",
    "    # tb = SummaryWriter()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "\n",
    "        # Loop over each batch in the dataset\n",
    "        for batch in tqdm(train_loader):\n",
    "            # TODO: Backpropagation and gradient descent\n",
    "            images, labels = batch\n",
    "            labels = torch.stack(list(labels), dim=0)\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()       # Compute gradients\n",
    "            optimizer.step()      # Update all the weights with the gradients you just calculated\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Periodically evaluate our model + log to Tensorboard\n",
    "            if step % n_eval == 0:\n",
    "                model.eval()\n",
    "                # TODO:\n",
    "                # Compute training loss and accuracy.\n",
    "                # Log the results to Tensorboard.\n",
    "\n",
    "                writer.add_scalar(\"Loss/train\", loss.mean().item(), epoch + 1)\n",
    "\n",
    "                # TODO:\n",
    "                # Compute validation loss and accuracy.\n",
    "                # Log the results to Tensorboard.\n",
    "                # Don't forget to turn off gradient calculations!\n",
    "                \n",
    "                vloss, vaccuracy = evaluate(val_loader, model, loss_fn, device)\n",
    "                writer.add_scalar(\"Loss/val\", vloss, epoch + 1)\n",
    "                writer.add_scalar(\"Accuracy/val\", vaccuracy, epoch + 1)\n",
    "                model.train()\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print('Epoch:', epoch + 1, 'Loss:', loss.item())\n",
    "\n",
    "    writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   accuracy compute\n",
    "\n",
    "def compute_accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a model's predictions.\n",
    "\n",
    "    Example input:\n",
    "        outputs: [0.7, 0.9, 0.3, 0.2]\n",
    "        labels:  [1, 1, 0, 1]\n",
    "\n",
    "    Example output:\n",
    "        0.75\n",
    "    \"\"\"\n",
    "\n",
    "    n_correct = (outputs == labels).int().sum()\n",
    "    n_total = len(outputs)\n",
    "    return n_correct / n_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   validation eval function\n",
    "\n",
    "def evaluate(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    Computes the loss and accuracy of a model on the validation dataset.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad(): # IMPORTANT: turn off gradient computations\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # labels == predictions does an elementwise comparison\n",
    "            # e.g.                labels = [1, 2, 3, 4]\n",
    "            #                predictions = [1, 4, 3, 3]\n",
    "            #      labels == predictions = [1, 0, 1, 0]  (where 1 is true, 0 is false)\n",
    "            # So the number of correct predictions is the sum of (labels == predictions)\n",
    "            correct += (labels == predictions).int().sum()\n",
    "            total += len(predictions)\n",
    "            loss += loss_fn(outputs, labels).mean().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return loss/len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to run tensorboard visualization of acc/loss/val\n",
    "# install via \n",
    "#   conda install tensorboard\n",
    "# run to visualize\n",
    "#   tensorboard --logdir <dir>\n",
    "# our dir is runs\n",
    "# Once run, open local host in webpage\n",
    "# delete useles logs from runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1\n",
      "Batch size: 16\n",
      "Epoch 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1110 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#   main\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Get command line arguments\n",
    "hyperparameters = {\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE}\n",
    "\n",
    "# Add GPU support. This line of code might be helpful.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "# Initalize dataset and model. Then train the model!\n",
    "data = StartingDataset(\"/train/\")\n",
    "train_size = int(0.7 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "model = StartingNetwork()\n",
    "starting_train(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    model=model,\n",
    "    hyperparameters=hyperparameters,\n",
    "    n_eval=N_EVAL,\n",
    "    device = device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9b712ea729e402836c5595724b4e6d35efa45a29af25a2578c0523890674d22"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

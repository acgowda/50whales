{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Tejas Kamtam\n",
    "#   Anand Gowda\n",
    "#   Austin Yang\n",
    "#   Anish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   constants\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "N_EVAL = 1\n",
    "DATA = \"../50whales/sauce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   data processing\n",
    "import torch\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class StartingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that contains 100000 3x224x224 black images (all zeros).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data = pd.read_csv(DATA + \"/train.csv\")\n",
    "        self.data.rename(columns=self.data.iloc[0]).drop(self.data.index[0])\n",
    "        self.images = self.data.iloc[:, 0]\n",
    "        self.labels = self.data.iloc[:, 1]\n",
    "        self.transition = list(set(self.labels))\n",
    "        self.whales = self.labels.replace(self.transition, list(range(5005)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(DATA + self.path + self.images[index])\n",
    "        label = self.whales[index]\n",
    "\n",
    "        image = image.resize((448, 224))\n",
    "        image = ImageOps.grayscale(image)\n",
    "\n",
    "        #return torchvision.transforms.functional.pil_to_tensor(image), label\n",
    "        image = torchvision.transforms.ToTensor()(np.array(image))\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class StartingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic logistic regression on 224x224x3 images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size = 5, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 56 * 28, 5005)\n",
    "        # self.fc2 = nn.Linear(20020, 10010)\n",
    "        # self.fc3 = nn.Linear(10010 ,5005)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "\n",
    "        #Forward porp\n",
    "        # (n, 1, 448, 224)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        # (n, 4, 448, 224)\n",
    "        x = self.pool(x)\n",
    "        # (n, 4, 224, 112)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        # (n, 8, 224, 112)\n",
    "        x = self.pool(x)\n",
    "        # (n, 8, 112, 56)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        # (n, 16, 112, 56)\n",
    "        x = self.pool(x)\n",
    "        # (n, 16, 56, 28)\n",
    "\n",
    "        x = torch.reshape(x, (-1, 16 * 56 * 28))\n",
    "        # (n, 8 * 112 * 56)\n",
    "        x = self.fc1(x)\n",
    "        # x = F.relu(x)\n",
    "        # (n, 20020)\n",
    "        # x = self.fc2(x)\n",
    "        # x = F.relu(x)\n",
    "        # (n, 10010)\n",
    "        # x = self.fc3(x)\n",
    "        # (n, 5005)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   train function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def starting_train(train_dataset, val_dataset, model, hyperparameters, n_eval, device):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model.\n",
    "\n",
    "    Args:\n",
    "        train_dataset:   PyTorch dataset containing training data.\n",
    "        val_dataset:     PyTorch dataset containing validation data.\n",
    "        model:           PyTorch model to be trained.\n",
    "        hyperparameters: Dictionary containing hyperparameters.\n",
    "        n_eval:          Interval at which we evaluate our model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get keyword arguments\n",
    "    batch_size, epochs = hyperparameters[\"batch_size\"], hyperparameters[\"epochs\"]\n",
    "\n",
    "    # Initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Initalize optimizer (for gradient descent) and loss function\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Move the model to the GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    step = 1\n",
    "\n",
    "    # tb = SummaryWriter()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "\n",
    "        # Loop over each batch in the dataset\n",
    "        for batch in tqdm(train_loader):\n",
    "            # TODO: Backpropagation and gradient descent\n",
    "            images, labels = batch\n",
    "            labels = torch.stack(list(labels), dim=0)\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()       # Compute gradients\n",
    "            optimizer.step()      # Update all the weights with the gradients you just calculated\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Periodically evaluate our model + log to Tensorboard\n",
    "            # if step % n_eval == 0:\n",
    "                # TODO:\n",
    "                # Compute training loss and accuracy.\n",
    "                # Log the results to Tensorboard.\n",
    "\n",
    "                # with torch.no_grad():\n",
    "                #     images = images.to(device)\n",
    "                #     labels = labels.to(device)\n",
    "\n",
    "                #     predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                #     accuracy = compute_accuracy(predictions, labels)\n",
    "                #     print('Accuracy: ', accuracy)\n",
    "\n",
    "                # TODO:\n",
    "                # Compute validation loss and accuracy.\n",
    "                # Log the results to Tensorboard.\n",
    "                # Don't forget to turn off gradient calculations!\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "    evaluate(val_loader, model, loss_fn, device)\n",
    "    # tb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   accuracy compute\n",
    "def compute_accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a model's predictions.\n",
    "\n",
    "    Example input:\n",
    "        outputs: [0.7, 0.9, 0.3, 0.2]\n",
    "        labels:  [1, 1, 0, 1]\n",
    "\n",
    "    Example output:\n",
    "        0.75\n",
    "    \"\"\"\n",
    "\n",
    "    n_correct = (outputs == labels).int().sum()\n",
    "    n_total = len(outputs)\n",
    "    return n_correct / n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   validation eval function\n",
    "def evaluate(val_loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    Computes the loss and accuracy of a model on the validation dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad(): # IMPORTANT: turn off gradient computations\n",
    "        for batch in val_loader:\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # labels == predictions does an elementwise comparison\n",
    "            # e.g.                labels = [1, 2, 3, 4]\n",
    "            #                predictions = [1, 4, 3, 3]\n",
    "            #      labels == predictions = [1, 0, 1, 0]  (where 1 is true, 0 is false)\n",
    "            # So the number of correct predictions is the sum of (labels == predictions)\n",
    "            correct += (labels == predictions).int().sum()\n",
    "            total += len(predictions)\n",
    "            loss += loss_fn(outputs, labels)\n",
    "\n",
    "    \n",
    "        print(correct / total)\n",
    "    model.train()\n",
    "\n",
    "    # tb.add_scalar(\"Loss\", loss, epoch)\n",
    "    # tb.add_scalar(\"Correct\", correct, epoch)\n",
    "    # tb.add_scalar(\"Accuracy\", correct / total, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1\n",
      "Batch size: 16\n",
      "Epoch 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1110 [00:00<?, ?it/s]/home/tejaskamtam/miniconda3/envs/acm/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-1_ic8ial/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "#   main\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Get command line arguments\n",
    "hyperparameters = {\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE}\n",
    "\n",
    "# Add GPU support. This line of code might be helpful.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "# Initalize dataset and model. Then train the model!\n",
    "data = StartingDataset(\"/train/\")\n",
    "train_size = int(0.7 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "model = StartingNetwork()\n",
    "starting_train(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    model=model,\n",
    "    hyperparameters=hyperparameters,\n",
    "    n_eval=N_EVAL,\n",
    "    device = device\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9b712ea729e402836c5595724b4e6d35efa45a29af25a2578c0523890674d22"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
